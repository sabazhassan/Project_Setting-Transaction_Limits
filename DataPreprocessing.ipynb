{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# function to cleanup and bin categories in demographic data\n",
    "\n",
    "def  cleanup_demographics(data):\n",
    "    # remove rows with no country and birthyear information\n",
    "    data = data.dropna(subset = [\"COUNTRY_CODE\", \"BIRTH_YEAR\"])\n",
    "\n",
    "    cols = ['EXCHANGE_ACCOUNT_ID', 'level', 'CREATED_AT', 'FIRST_VERIFIED_AT',\n",
    "       'STATE_CODE', 'COUNTRY_CODE', 'BIRTH_YEAR', 'OCCUPATION','SESSION_COUNT',\n",
    "       'COUNT_BANKS']\n",
    "    data = data[cols]\n",
    "    data[\"FIRST_VERIFIED_AT\"] = pd.to_datetime(data[\"FIRST_VERIFIED_AT\"])\n",
    "    data[\"CREATED_AT\"] = np.where(data[\"CREATED_AT\"]=='1/0/00',data[\"FIRST_VERIFIED_AT\"], data[\"CREATED_AT\"] )\n",
    "    data[\"CREATED_AT\"] = pd.to_datetime(data[\"CREATED_AT\"])\n",
    "    data[\"DAYS_TO_VERIFY\"] = (data[\"CREATED_AT\"]- data[\"FIRST_VERIFIED_AT\"])\n",
    "    data[\"DAYS_TO_VERIFY\"] = data[\"DAYS_TO_VERIFY\"].dt.days\n",
    "    data[\"AGE\"] = (datetime.datetime.now().year- data[\"BIRTH_YEAR\"]).astype(int)\n",
    "    data[\"COUNT_BANKS\"]= data[\"COUNT_BANKS\"].fillna(1)\n",
    "    #create bins for Age\n",
    "    age_levels= [19,30,40,50,60,70,80,98]\n",
    "    data = category_bins(data,\"AGE\", age_levels)\n",
    "    days_to_verify_levels = [-1,7,30,90,180,365,1148]\n",
    "    data = category_bins(data, \"DAYS_TO_VERIFY\", days_to_verify_levels)\n",
    "    # clean states\n",
    "    data_states = cleanup_states(data)\n",
    "    # clean countries\n",
    "    data_country = clean_countries(data_states)\n",
    "    # categorize similar occupation into broader buckets together\n",
    "    df_occ = categorize_occupation(data_country)\n",
    "    return df_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cleanup  and aggregate in Transfers data\n",
    "\n",
    "def cleanup_transfers(data):\n",
    "    data['TX_YEAR'] = pd.to_datetime(data['TX_TIME']).dt.to_period('Y')\n",
    "    data[\"ACCOUNT_ID\"] = data[\"ACCOUNT_ID\"].astype(int)\n",
    "    data[\"AMOUNT\"] = data[\"AMOUNT\"].astype(int)\n",
    "    data = data.rename(columns = {\"ACCOUNT_ID\":\"EXCHANGE_ACCOUNT_ID\" })\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def transfer_agg(transfers_train_encoded):  \n",
    "    cols = transfers_train_encoded.columns[1:]\n",
    "    transfers_agg_dict  = {c: 'max' for i, c in enumerate(cols)}\n",
    "    amount = {'AMOUNT': \"sum\"}\n",
    "    transfers_agg_dict.update(amount)\n",
    "    transfers_agg_dict\n",
    "    transfers_train_agg = transfers_train_encoded.groupby(\"EXCHANGE_ACCOUNT_ID\").agg(transfers_agg_dict).reset_index()\n",
    "    transfers_train_agg = transfers_train_agg.set_index(\"EXCHANGE_ACCOUNT_ID\")\n",
    "    return transfers_train_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to  cleanup and aggregate Exposure data\n",
    "\n",
    "\n",
    "def exposure_agg(exposure_train_encoded):\n",
    "    exposure_train_agg = exposure_train_encoded.groupby(\"EXCHANGE_ACCOUNT_ID\").agg({'category_1':'max', 'category_10':'max', 'category_11':'max',\n",
    "       'category_12':'max', 'category_13':'max', 'category_14':'max', 'category_15':'max',\n",
    "       'category_2':'max', 'category_3':'max', 'category_4':'max', 'category_5':'max', 'category_6':'max',\n",
    "       'category_7':'max', 'category_8':'max', 'category_9':'max','SENT_INDIRECT_EXPOSURE':'sum', 'SENT_DIRECT_EXPOSURE':'sum',\n",
    "       'RECEIVED_INDIRECT_EXPOSURE':'sum', 'RECEIVED_DIRECT_EXPOSURE':'sum'}).reset_index()\n",
    "    exposure_train_agg = exposure_train_agg.set_index(\"EXCHANGE_ACCOUNT_ID\")\n",
    "    return exposure_train_agg\n",
    "\n",
    "# function to clean up states - ended up dropping the colunmn as it has many categories\n",
    "\n",
    "def cleanup_states(data):\n",
    "    data['STATE_CODE'] = data['STATE_CODE'].fillna(\"others\")\n",
    "    data['STATE_CODE']= [item.strip() for item in data['STATE_CODE'].str.lower()]\n",
    "    data['STATE_CODE'] = data['STATE_CODE'].map(state_dict).fillna(data['STATE_CODE'])\n",
    "    final_data = convertstates(data)\n",
    "    return final_data\n",
    "\n",
    "\n",
    "\n",
    "# function to clean up states\n",
    "\n",
    "def clean_countries(data):\n",
    "    data['COUNTRY_CODE']= data['COUNTRY_CODE'].str.lower()\n",
    "    #print(data['COUNTRY_CODE'].unique())\n",
    "    df = convertCattoNumeric(data, \"COUNTRY_CODE\")\n",
    "    return df\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical to numerical for each state and country\n",
    "def convertstates(data):\n",
    "    data_int = pd.DataFrame()\n",
    "\n",
    "    for j in data['COUNTRY_CODE'].unique():\n",
    "        l = data[(data['COUNTRY_CODE'] == j)]\n",
    "        len_state = len(l['STATE_CODE'].unique())\n",
    "        arr_state1 = l['STATE_CODE'].unique()\n",
    "\n",
    "        if len_state != 1:\n",
    "            arr_state2 = [i for i in range(1,len_state+1)]\n",
    "        else:\n",
    "            arr_state2 = [1]\n",
    "\n",
    "        state_dict = dict(zip(arr_state1, arr_state2))        \n",
    "        l['STATE_CODE_INT'] = l['STATE_CODE'].map(state_dict)\n",
    "        data_int = data_int.append(l)\n",
    "    return data_int\n",
    "\n",
    "\n",
    "def convertCattoNumeric(df, colname):\n",
    "    uni = df[colname].unique()\n",
    "    col_int =[i for i in range(len(uni))]\n",
    "    cat_int_dict = dict(zip(uni, col_int))\n",
    "    #print(cat_int_dict)\n",
    "    colname_new = colname+'_INT'\n",
    "    df[colname_new] = df[colname].map(cat_int_dict).astype(int)\n",
    "    return df# function to clean up occupation\n",
    "\n",
    "def categorize_occupation(df2):\n",
    "    df2['OCCUPATION'] = df2['OCCUPATION'].fillna(\"unknown\")\n",
    "    df2[\"OCCUPATION\"] = df2['OCCUPATION'].str.lower()\n",
    "    df2[\"OCC_CAT\"] = np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(business)),\"business\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(tech)),\"tech\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(management)),\"management\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(finance)),\"finance\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(consultant)),\"consultant\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(acad)),\"acad\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(health)),\"health\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(law)),\"law\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(marketing)),\"marketing\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(accounting)),\"accounting\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(unemployed)),\"unemployed\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(writer)),\"writer\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(construction)),\"construction\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(artist)),\"artist\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(driver)),\"driver\",\n",
    "                         np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(designer)),\"designer\",\n",
    "                        np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(pilot)),\"pilot\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(sports)),\"sports\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(military)),\"military\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(insurance)),\"insurance\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(architect)),\"architect\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(musician)),\"musician\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(photographer)),\"photographer\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"|\".join(retired)),\"retired\",\n",
    "                          np.where(df2[\"OCCUPATION\"].str.contains(\"unknown\"),\"unknown\",                   \n",
    "\n",
    "                         \"other\")))))))))))))))))))))))))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create bins - ended up using continous data for more variability\n",
    "def category_bins(df, col, bins):\n",
    "    df[col+'_GROUPS'] = pd.cut(df[col], bins=bins, labels = [i for i in range(1,len(bins))])   \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dummy variables via onehot encoding\n",
    "\n",
    "\n",
    "def one_hot_ecoding(df, cols):\n",
    "    feature_df = df[cols]\n",
    "    onehot_df = pd.get_dummies(feature_df, columns = cols)\n",
    "    demo_cat_onehot_drop = df.drop(cols, axis = 1)\n",
    "    demo_cat_onehot = pd.concat([demo_cat_onehot_drop, onehot_df], axis = 1)\n",
    "    return demo_cat_onehot\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
